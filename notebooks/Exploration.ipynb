{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d4cb248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pprint as pp\n",
    "\n",
    "import sindy\n",
    "import sindy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "713ea9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolynomialLibrary:\n",
    "    def __init__(self, max_degree=2, cross_terms=True):\n",
    "        self.max_degree = max_degree\n",
    "        self.cross_terms = cross_terms\n",
    "        \n",
    "    def get_candidates(self, dim, feature_names):\n",
    "        self.feature_names = feature_names\n",
    "        return [self.__polynomial(degree_sequence) \n",
    "                    for degree in range(1,self.max_degree+1)\n",
    "                        for degree_sequence in self.__get_degree_sequences(degree, dim)]\n",
    "    \n",
    "    \n",
    "    def __polynomial(self, degree_sequence):\n",
    "        def fn(X):\n",
    "            terms = torch.stack( tuple(X[:,i]**d for i,d in enumerate(degree_sequence)), axis=1 )\n",
    "            return torch.prod(terms, dim=1)\n",
    "        fn_name = ' '.join(self.__display_term(self.feature_names[i],d) for i,d in enumerate(degree_sequence) if d)    \n",
    "        return (fn, fn_name)\n",
    "    \n",
    "    def __display_term(self, feature_name, d):\n",
    "        if d == 1:\n",
    "            return f'{feature_name}'\n",
    "        return f'{feature_name}^{d}'\n",
    "    \n",
    "    def __get_degree_sequences(self, degree, num_terms):\n",
    "        if num_terms == 1:  return [[degree]]\n",
    "        if degree == 0:     return [[0 for _ in range(num_terms)]]\n",
    "        res = []\n",
    "        for d in reversed(range(degree+1)):\n",
    "            for seq in self.__get_degree_sequences(degree-d, num_terms-1):\n",
    "                res.append([d, *seq])\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "aff63082",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrigLibrary:\n",
    "    def __init__(self):\n",
    "        self.max_freq = 1\n",
    "    \n",
    "    def get_candidates(self, dim, feature_names):\n",
    "        self.feature_names = feature_names\n",
    "        return [trig(i) for trig in [self.__sin, self.__cos] for i in range(dim)]\n",
    "\n",
    "    def __sin(self,i):\n",
    "        fn      = lambda X: torch.sin(X[:,i])\n",
    "        fn_name = f'sin({self.feature_names[i]})'\n",
    "        return (fn, fn_name)\n",
    "\n",
    "    def __cos(self,i):\n",
    "        fn      = lambda X: torch.cos(X[:,i])\n",
    "        fn_name = f'cos({self.feature_names[i]})'\n",
    "        return (\n",
    "            fn,\n",
    "            fn_name\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f4f3e764",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SINDy(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        X, \n",
    "        X_dot=None, \n",
    "        libs=None, \n",
    "        feature_names=None\n",
    "    ):\n",
    "        super(SINDy, self).__init__()\n",
    "\n",
    "        n,m = X.size()\n",
    "        if feature_names == None:\n",
    "            feature_names = [f'x{i+1}' for i in range(m)]\n",
    "\n",
    "        self.X = X\n",
    "        self.X_dot = X_dot\n",
    "        self.feature_names = feature_names\n",
    "        self.num_features  = m\n",
    "        self.num_snapshots = n\n",
    "\n",
    "        self.candidate_terms = [ lambda x: torch.ones(self.num_snapshots) ]\n",
    "        self.candidate_names = ['1']\n",
    "        for lib in libs:\n",
    "            lib_candidates = lib.get_candidates(self.num_features, feature_names)\n",
    "            for term, name in lib_candidates:\n",
    "                self.candidate_terms.append(term)\n",
    "                self.candidate_names.append(name)\n",
    "\n",
    "        self.SINDy_forward = nn.Linear(\n",
    "            len(self.candidate_terms), \n",
    "            self.num_features, \n",
    "            bias=False\n",
    "        )\n",
    "        \n",
    "    def library(self):\n",
    "        print('library candidate terms:')\n",
    "        return self.candidate_names\n",
    "    \n",
    "    def model_parameters(self):\n",
    "        params = list(self.parameters())[0]\n",
    "        return params\n",
    "    \n",
    "    def theta(self,X):\n",
    "        return torch.stack(tuple(f(X) for f in self.candidate_terms), axis=1)\n",
    "\n",
    "    def forward(self):\n",
    "        theta_X = self.theta(self.X)\n",
    "        \n",
    "        # X_dot_predict = f(X) = Θ(X)Ξ = Θ(X)[ ξ1, ξ2, ..., ξn ]\n",
    "        X_dot_predict = self.SINDy_forward(theta_X)\n",
    "        return X_dot_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "938c43df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "library candidate terms:\n",
      "['1', 'x', 'y', 'sin(x)', 'sin(y)', 'cos(x)', 'cos(y)']\n",
      "Parameter containing:\n",
      "tensor([[ 0.2261,  0.2323,  0.0628, -0.3528, -0.2212,  0.0820,  0.1814],\n",
      "        [-0.3231, -0.0957,  0.1266, -0.1699, -0.2336, -0.0842,  0.1476]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "t = torch.linspace(0,2,100)\n",
    "\n",
    "x = 10 * torch.exp(- 0.5 * t)\n",
    "y = -2 * torch.exp(3 * t)\n",
    "\n",
    "x_dot = - 0.5 * x\n",
    "y_dot = 3 * y\n",
    "\n",
    "X = torch.stack((x,y), dim=-1)\n",
    "X_dot = torch.stack((x_dot,y_dot), dim=-1)\n",
    "X[:5]\n",
    "\n",
    "X_dot[:5,:]\n",
    "###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "libs  = [\n",
    "  PolynomialLibrary(max_degree=1),\n",
    "  TrigLibrary()\n",
    "]\n",
    "\n",
    "sindy = SINDy(\n",
    "    X, \n",
    "    X_dot=X_dot, \n",
    "    libs=libs,\n",
    "    feature_names=['x', 'y']\n",
    ")\n",
    "\n",
    "print(sindy.library())\n",
    "print(sindy.model_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "a977606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_2 = lambda X: torch.linalg.norm(X)\n",
    "\n",
    "loss_fn = lambda X, X_pred: norm_2(X - X_pred)\n",
    "optimizer = torch.optim.Adam(sindy.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b8ddf66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4432.2881, grad_fn=<CopyBackwards>)\n",
      "tensor(2011.3049, grad_fn=<CopyBackwards>)\n",
      "tensor(139.3008, grad_fn=<CopyBackwards>)\n",
      "tensor(50.0098, grad_fn=<CopyBackwards>)\n",
      "tensor(14.3307, grad_fn=<CopyBackwards>)\n",
      "tensor(4.2473, grad_fn=<CopyBackwards>)\n",
      "tensor(0.2830, grad_fn=<CopyBackwards>)\n",
      "tensor(0.1685, grad_fn=<CopyBackwards>)\n",
      "tensor(0.1179, grad_fn=<CopyBackwards>)\n",
      "tensor(0.1006, grad_fn=<CopyBackwards>)\n",
      "library candidate terms:\n",
      "['1', 'x', 'y', 'sin(x)', 'sin(y)', 'cos(x)', 'cos(y)']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-3.2458e-05, -5.0001e-01,  1.2664e-05,  1.0294e-05, -1.2325e-05,\n",
       "          1.6318e-05, -1.2232e-05],\n",
       "        [-6.8776e-03,  8.7697e-04,  3.0000e+00, -7.9391e-04,  9.5288e-05,\n",
       "          1.2906e-03,  1.2643e-04]], requires_grad=True)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10000\n",
    "\n",
    "for t in range(epochs):\n",
    "    \n",
    "    X_dot_pred = sindy()\n",
    "    loss = loss_fn(X_dot, X_dot_pred)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if t % 1000 == 0:\n",
    "        print(loss)\n",
    "\n",
    "print(sindy.library())\n",
    "sindy.model_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac5d6af0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "iterable unpacking cannot be used in comprehension (<ipython-input-42-07de3f337327>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-42-07de3f337327>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    [*x for x in [x1,x2]]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m iterable unpacking cannot be used in comprehension\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "])\n",
    "x2 = x1 * 10\n",
    "[*x for x in [x1,x2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "da9b28fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Test, self).__init__()\n",
    "        self.Test_forward = nn.Linear(\n",
    "            10, \n",
    "            2, \n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        X_predict = self.Test_forward(X)\n",
    "        return X_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "1bdb8711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9974,  1.2344,  0.9949,  ..., -1.7614,  0.1701, -0.3766],\n",
       "        [ 0.3847,  1.0268,  0.3578,  ..., -0.9790,  0.5058, -1.0094],\n",
       "        [-0.6239, -0.6261,  1.4587,  ...,  0.1791, -0.3129,  0.0420],\n",
       "        ...,\n",
       "        [-0.4159,  1.2797,  0.1997,  ..., -0.1224, -0.4279, -0.7940],\n",
       "        [ 1.4913, -0.2421, -1.5575,  ..., -1.4920, -0.1720,  1.0254],\n",
       "        [-0.6490, -1.7032,  1.5738,  ..., -0.4284,  0.1467, -0.5945]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(1000,10)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "167b6c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_pred shape: \n",
      "torch.Size([1000, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4246,  0.5870],\n",
       "        [-0.0685, -0.9148],\n",
       "        [-0.1895,  0.6369],\n",
       "        ...,\n",
       "        [-0.4202,  0.4014],\n",
       "        [-0.3995,  0.3701],\n",
       "        [ 0.6987, -0.5694]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Test()\n",
    "\n",
    "X_pred = model(X)\n",
    "print(f'X_pred shape: \\n{X_pred.size()}')\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c68e9c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (98) must match the size of tensor b (3) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2f830b045d50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mX_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_dot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspacing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (98) must match the size of tensor b (3) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "t = torch.linspace(0,2,100)\n",
    "\n",
    "x = 10 * torch.exp(- 0.5 * t)\n",
    "y = -2 * torch.exp(3 * t)\n",
    "\n",
    "x_dot = - 0.5 * x\n",
    "y_dot = 3 * y\n",
    "\n",
    "X = torch.stack((x,y), dim=-1)\n",
    "X_dot = torch.stack((x_dot,y_dot), dim=-1)\n",
    "dX = torch.gradient(X[:5],spacing = (t,))\n",
    "X[:5]\n",
    "\n",
    "print(X_dot[:5,:])\n",
    "print(dX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ccee64c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (18) must match the size of tensor b (0) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8b7a2301553e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdf_actual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (18) must match the size of tensor b (0) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "t = torch.linspace(0,2,20)\n",
    "f1 = t**2\n",
    "f2 = torch.exp(-2 * t)\n",
    "df1 = 2 * t\n",
    "df2 = -2 * torch.exp(-2 * t)\n",
    "\n",
    "f = torch.stack((f1,f2), dim=-1).T\n",
    "f\n",
    "df = torch.gradient(f, spacing=(t,t))\n",
    "df_actual = torch.stack((df1, df2), dim=-1)\n",
    "\n",
    "print(df)\n",
    "print(df_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bece2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f99a3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c62affe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa37067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dedd237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74f834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CandidateLibraryGenerator:\n",
    "#     def __init__(\n",
    "#       self, \n",
    "#       num_snapshots,\n",
    "#       num_state_variables,\n",
    "#       max_polynomial_degree = 2,\n",
    "#       cross_terms = True, \n",
    "#       trig = False, \n",
    "#       feature_names = None\n",
    "#     ):\n",
    "#         if feature_names == None:\n",
    "#             feature_names = [f'x{i+1}' for i in range(num_snapshots)] \n",
    "\n",
    "#         if len(feature_names) != num_state_variables:\n",
    "#             raise ValueError('number of feature_names does not match number of features')\n",
    "\n",
    "#         self.feature_names       = feature_names         # feature names\n",
    "#         self.num_snapshots       = num_snapshots         # number of rows in X\n",
    "#         self.num_state_variables = num_state_variables   # number of cols in X\n",
    "\n",
    "#         constant_fn = {\n",
    "#           'fn': lambda x: torch.ones(self.num_snapshots),\n",
    "#           'fn_name': '1'\n",
    "#         }\n",
    "\n",
    "#         polynomial_terms = self.__get_polynomial_terms(max_polynomial_degree)\n",
    "#         trig_terms = self.__get_trig_terms(num_state_variables) if trig else []\n",
    "\n",
    "#         candidates         = [constant_fn, *polynomial_terms, *trig_terms]\n",
    "#         candidate_fns      = [candidate['fn']      for candidate in candidates]\n",
    "#         candidate_fn_names = [candidate['fn_name'] for candidate in candidates]\n",
    "\n",
    "#         self.candidate_functions      = candidate_fns         # 1-d python list of candidate functions\n",
    "#         self.candidate_function_names = candidate_fn_names    # 1-d python list of candidate function names\n",
    "#         self.num_candidate_functions  = len(candidate_fns)    # num columns in theta(X)\n",
    "\n",
    "#     def __call__(self, X):\n",
    "#         if not isinstance(X, torch.Tensor):\n",
    "#             raise ValueError('Input X must be of type torch.Tensor') \n",
    "\n",
    "#         if X.dim() != 2:\n",
    "#             raise ValueError('Input X does is not tensor of dim 2.')\n",
    "\n",
    "#         if X.size() != (self.num_snapshots, self.num_state_variables):\n",
    "#             raise ValueError(\n",
    "#                 f'Bad dimensions. Input must be a {self.num_snapshots} x {self.num_state_variables} matrix.'\n",
    "#             )\n",
    "\n",
    "#         return torch.stack(tuple(fn(X) for fn in self.candidate_functions), axis=1)\n",
    "\n",
    "#     '''\n",
    "#     private methods_____________________________________________\n",
    "#     '''\n",
    "#     def __get_polynomial_terms(self, max_degree):\n",
    "#         return [self.__polynomial(degree_sequence) \n",
    "#             for degree in range(1,max_degree+1)\n",
    "#                 for degree_sequence in self.__get_degree_sequences(degree, self.num_state_variables)]\n",
    "\n",
    "#     def __get_trig_terms(self, n):\n",
    "#         return [trig(i) for trig in [self.__sin, self.__cos] for i in range(n)]\n",
    "\n",
    "#     def __sin(self,i):\n",
    "#         return {\n",
    "#             'fn': lambda X: torch.sin(X[:,i]),\n",
    "#             'fn_name': f'sin({self.feature_names[i]})'\n",
    "#         }\n",
    "\n",
    "#     def __cos(self,i):\n",
    "#         return {\n",
    "#             'fn': lambda X: torch.cos(X[:,i]),\n",
    "#             'fn_name': f'cos({self.feature_names[i]})'\n",
    "#         }\n",
    "\n",
    "#     def __polynomial(self, degree_sequence):\n",
    "#         def fn(X):\n",
    "#             terms = torch.stack( tuple(X[:,i]**d for i,d in enumerate(degree_sequence)), axis=1 )\n",
    "#             return torch.prod(terms, dim=1)\n",
    "\n",
    "#         fn_name = ' '.join(f'{self.feature_names[i]}^{d}' for i,d in enumerate(degree_sequence) if d)    \n",
    "#         return {\n",
    "#             'fn': fn,\n",
    "#             'fn_name': fn_name\n",
    "#         }\n",
    "\n",
    "#     def __get_degree_sequences(self, degree, num_terms):\n",
    "#         if num_terms == 1:  return [[degree]]\n",
    "#         if degree == 0:     return [[0 for _ in range(num_terms)]]\n",
    "#         res = []\n",
    "#         for d in reversed(range(degree+1)):\n",
    "#             for seq in self.__get_degree_sequences(degree-d, num_terms-1):\n",
    "#                 res.append([d, *seq])\n",
    "#         return res\n",
    "\n",
    "#     def __repr__(self):\n",
    "#         return f'CandidateLibraryGenerator({self.num_snapshots}, {self.num_state_variables})'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoSINDy",
   "language": "python",
   "name": "autosindy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
